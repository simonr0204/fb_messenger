{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook chat friend emulator\n",
    "\n",
    "This is an LSTM RNN for producing sentences in the style of a given facebook friend, based on our message history\n",
    "\n",
    "Apologies in advance to my guinea-pig, Dmitri. I censored the ramblings of your robot self to make sure you didn't say anything too outrageous!\n",
    "\n",
    "TO DO : create chat-bot with a message-response sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "import keras.utils as ku \n",
    "import json\n",
    "import glob\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of friend to emulate and some hyperparameters\n",
    "friend = 'Dmitri'\n",
    "num_messages = 7000    #randomly sample n messages from the friend's corpus\n",
    "max_length = 20         #trim all messages to this many words. Most messages are short, and longer lengthen the training time significantly\n",
    "lstm_size=100       #Size of the  LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(friend, num_messages, max_length):\n",
    "\n",
    "    PATH_TO_CONV = glob.glob(f'data/messages/inbox/{friend}*/message.json')[0]  #data has weird names but they start with first name so match\n",
    "    \n",
    "    with open(PATH_TO_CONV) as f:\n",
    "        data = json.load(f)\n",
    "                                \n",
    "    data = pd.DataFrame(data['messages'])\n",
    "\n",
    "    def rename(name):\n",
    "        if name=='Simon Roberts':\n",
    "            return 'Me'\n",
    "        else:\n",
    "            return friend\n",
    "        \n",
    "    def trim_message(message):\n",
    "        trimmed = str(message).split(' ')[:max_length]\n",
    "        return ' '.join(trimmed)\n",
    "    \n",
    "    data['sender_name'] = data['sender_name'].apply(rename)   #rename senders to 'Me' and 'First Name'\n",
    "    data['content'] = data[data['content'].apply(type)==str]['content'] #Only use messages which are strings (so just numbers are dropped)\n",
    "    \n",
    "    messages = data[data['sender_name']==friend]['content'].apply(trim_message)  #trim messages to N words\n",
    "\n",
    "    def clean_text(txt):\n",
    "        txt=str(txt)\n",
    "        txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "        txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "        return txt \n",
    "\n",
    "    return [clean_text(message) for message in sample(list(messages), num_messages)]  #Gets N random messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would you still be as convinced then',\n",
       " 'and making record highs at exponential pace while ether rallies slowly',\n",
       " 'and tower of london in the background',\n",
       " 'is def not cos im taking it as given ',\n",
       " 'but im all for pubg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate the corpus, and look at a few examples\n",
    "corpus = generate_corpus(friend, num_messages, max_length)\n",
    "sample(corpus, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 23, 16)            99392     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               46800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6212)              627412    \n",
      "=================================================================\n",
      "Total params: 773,604\n",
      "Trainable params: 773,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 16, input_length=input_len))    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(lstm_size))            #Larger vocab probably required larger LSTM layer\n",
    "    model.add(Dropout(0.1))    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42510/42510 [==============================] - 10s 244us/step - loss: 7.0727\n",
      "Epoch 2/50\n",
      "42510/42510 [==============================] - 9s 203us/step - loss: 6.6802\n",
      "Epoch 3/50\n",
      "42510/42510 [==============================] - 9s 202us/step - loss: 6.5955\n",
      "Epoch 4/50\n",
      "42510/42510 [==============================] - 8s 191us/step - loss: 6.5106\n",
      "Epoch 5/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 6.4133\n",
      "Epoch 6/50\n",
      "42510/42510 [==============================] - 8s 197us/step - loss: 6.3126\n",
      "Epoch 7/50\n",
      "42510/42510 [==============================] - 8s 199us/step - loss: 6.2046\n",
      "Epoch 8/50\n",
      "42510/42510 [==============================] - 9s 203us/step - loss: 6.0884\n",
      "Epoch 9/50\n",
      "42510/42510 [==============================] - 8s 191us/step - loss: 5.9738\n",
      "Epoch 10/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 5.8628\n",
      "Epoch 11/50\n",
      "42510/42510 [==============================] - 8s 189us/step - loss: 5.7640\n",
      "Epoch 12/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 5.6751\n",
      "Epoch 13/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 5.5913\n",
      "Epoch 14/50\n",
      "42510/42510 [==============================] - 8s 196us/step - loss: 5.5156\n",
      "Epoch 15/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 5.4382\n",
      "Epoch 16/50\n",
      "42510/42510 [==============================] - 8s 191us/step - loss: 5.3625\n",
      "Epoch 17/50\n",
      "42510/42510 [==============================] - 8s 189us/step - loss: 5.2919\n",
      "Epoch 18/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 5.2174\n",
      "Epoch 19/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 5.1433\n",
      "Epoch 20/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 5.0708\n",
      "Epoch 21/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 4.9986\n",
      "Epoch 22/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 4.9255\n",
      "Epoch 23/50\n",
      "42510/42510 [==============================] - 8s 189us/step - loss: 4.8598\n",
      "Epoch 24/50\n",
      "42510/42510 [==============================] - 9s 201us/step - loss: 4.7902\n",
      "Epoch 25/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 4.7197\n",
      "Epoch 26/50\n",
      "42510/42510 [==============================] - 8s 196us/step - loss: 4.6569\n",
      "Epoch 27/50\n",
      "42510/42510 [==============================] - 8s 193us/step - loss: 4.5924\n",
      "Epoch 28/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 4.5274\n",
      "Epoch 29/50\n",
      "42510/42510 [==============================] - 8s 196us/step - loss: 4.4658\n",
      "Epoch 30/50\n",
      "42510/42510 [==============================] - 8s 196us/step - loss: 4.4025\n",
      "Epoch 31/50\n",
      "42510/42510 [==============================] - 8s 193us/step - loss: 4.3485\n",
      "Epoch 32/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 4.2897\n",
      "Epoch 33/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 4.2391\n",
      "Epoch 34/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 4.1843\n",
      "Epoch 35/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 4.1376\n",
      "Epoch 36/50\n",
      "42510/42510 [==============================] - 8s 197us/step - loss: 4.0883\n",
      "Epoch 37/50\n",
      "42510/42510 [==============================] - 8s 193us/step - loss: 4.0402\n",
      "Epoch 38/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 3.9988\n",
      "Epoch 39/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 3.9552\n",
      "Epoch 40/50\n",
      "42510/42510 [==============================] - 8s 194us/step - loss: 3.9215\n",
      "Epoch 41/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 3.8764\n",
      "Epoch 42/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 3.8392\n",
      "Epoch 43/50\n",
      "42510/42510 [==============================] - 8s 192us/step - loss: 3.8017\n",
      "Epoch 44/50\n",
      "42510/42510 [==============================] - 8s 195us/step - loss: 3.7702\n",
      "Epoch 45/50\n",
      "42510/42510 [==============================] - 8s 190us/step - loss: 3.7316\n",
      "Epoch 46/50\n",
      "42510/42510 [==============================] - 8s 196us/step - loss: 3.7040\n",
      "Epoch 47/50\n",
      "42510/42510 [==============================] - 8s 191us/step - loss: 3.6713\n",
      "Epoch 48/50\n",
      "42510/42510 [==============================] - 8s 189us/step - loss: 3.6443\n",
      "Epoch 49/50\n",
      "42510/42510 [==============================] - 8s 191us/step - loss: 3.6114\n",
      "Epoch 50/50\n",
      "42510/42510 [==============================] - 8s 193us/step - loss: 3.5871\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label, epochs=50, verbose=1, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{friend}_{num_messages}messages_{max_length}words_{lstm_size}lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to generate styled sentences based on a seed phrase\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robo-Dmitri: will you be a pilot to strike up to speed style transactions to be fresh for it and seriously first legs a\n",
      "\n",
      "Robo-Dmitri: I dont think it was spam to be in the meantime etc etc etc etc etc etc etc etc etc etc etc\n",
      "\n",
      "Robo-Dmitri: when can do it for a lot of the middle of creativity and its like walter tense to be honest in the\n",
      "\n",
      "Robo-Dmitri: I can do it for a danger of the best artistic experiences of the interviewer tiki taka in dortmund and br in\n",
      "\n",
      "Robo-Dmitri: obviously the point is just mostly pure arbitrage between dem p i circulated a dry heat ranging from 90120 f 3249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's see what he sounds like for some different starting words/phrases!\n",
    "texts = ['will you', 'I dont', 'when can', 'I can', 'obviously']\n",
    "\n",
    "for text in texts:\n",
    "    print(f'Robo-{friend}: {generate_text(text, 20, model,max_sequence_len)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually sounds a lot like Dmitri!\n",
    "\n",
    "To improve, smileys, standard texts like 'You sent a photo', etc. should either be removed or displayed in their entirety. As it is, we have their artifacts 'p' and 'D' in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
